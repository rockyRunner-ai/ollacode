# üöÄ ollacode

**Lightweight CLI Coding Assistant ‚Äî Ollama + Telegram**

A local AI coding assistant powered by `qwen3-coder:30b` via Ollama. Chat with your code through the terminal or Telegram ‚Äî read files, edit code, search your codebase, and run commands, all through natural language.

## ‚ú® Features

- üñ•Ô∏è **CLI Mode** ‚Äî Rich markdown rendering, code highlighting, real-time streaming
- üì± **Telegram Mode** ‚Äî Use your coding assistant remotely from anywhere
- ‚úèÔ∏è **Diff-based Editing** ‚Äî Smart search/replace file modifications (not full overwrites)
- üîç **Code Search** ‚Äî Grep-like content search across your project
- üìÅ **File Operations** ‚Äî Read, write, search files with workspace sandboxing
- ‚öôÔ∏è **Command Execution** ‚Äî Run shell commands with timeout protection
- üîê **Approval System** ‚Äî Review diffs before file changes are applied
- üìã **Project Memory** ‚Äî Auto-loads `OLLACODE.md` for project-specific context
- üîÑ **Agentic Loop** ‚Äî Automatic read ‚Üí edit ‚Üí verify ‚Üí fix cycles (up to 10 iterations)
- üí¨ **Conversation Context** ‚Äî Maintains chat history within sessions

## üèóÔ∏è Architecture

```mermaid
graph TD
    CLI["üñ•Ô∏è CLI - Rich\nStreaming + Approval UI"] --> Engine
    TG["üì± Telegram Bot\nPer-user Sessions"] --> Engine
    Engine["‚öôÔ∏è Conversation Engine\nHistory | Tool Orchestration\nAgentic Loop | Project Memory"]
    Engine --> Ollama["üîó Ollama Client\nhttpx async"]
    Engine --> Tools["üõ†Ô∏è Tool System\n7 tools"]
    Engine --> Prompts["üìã System Prompt\n+ OLLACODE.md Memory"]
    Ollama --> Server["üß† Ollama Server\nlocalhost:11434\nqwen3-coder:30b"]

    style CLI fill:#4a9eff,stroke:#2d7cd4,color:#fff
    style TG fill:#0088cc,stroke:#006699,color:#fff
    style Engine fill:#9b59b6,stroke:#7d3c98,color:#fff
    style Ollama fill:#e67e22,stroke:#d35400,color:#fff
    style Tools fill:#27ae60,stroke:#1e8449,color:#fff
    style Prompts fill:#f39c12,stroke:#d68910,color:#fff
    style Server fill:#2c3e50,stroke:#1a252f,color:#fff
```

## üì¶ Installation

```bash
# Clone the repo
git clone https://github.com/rockyRunner-ai/ollacode.git
cd ollacode

# Create virtual environment and install
python3 -m venv .venv
source .venv/bin/activate
pip install -e .

# Configure
cp .env.example .env
# Edit .env with your settings
```

## üîß Prerequisites

1. **Ollama** installed with your model:
   ```bash
   ollama pull qwen3-coder:30b
   ollama serve
   ```

2. **Telegram Bot** (optional):
   - Create a bot via [@BotFather](https://t.me/BotFather)
   - Set `TELEGRAM_BOT_TOKEN` in `.env`
   - Set `TELEGRAM_ALLOWED_USERS` with your User ID

## üöÄ Usage

### CLI Mode

```bash
ollacode cli                  # With approval prompts
ollacode cli --auto-approve   # Auto-approve all tool actions
```

### Telegram Mode

```bash
ollacode telegram
```

### Use a Different Model

```bash
ollacode cli --model llama3.1:8b
```

## üìå CLI Commands

| Command | Description |
|---------|-------------|
| `/help` | Show help |
| `/clear` | Reset conversation |
| `/model` | Show model info |
| `/approve` | Toggle auto-approve mode |
| `/quit` | Exit |

## üõ†Ô∏è Available Tools

The AI can use these tools to interact with your system:

| Tool | Description |
|------|-------------|
| `read_file` | Read file contents with line numbers |
| `write_file` | Create new files |
| `edit_file` | Modify existing files via search/replace |
| `list_directory` | List directory contents |
| `search_files` | Find files by glob pattern |
| `grep_search` | Search file contents (like grep) |
| `run_command` | Execute shell commands |

## üìã Project Memory

Create an `OLLACODE.md` file in your workspace root to provide project-specific context:

```markdown
# Project Rules
- Python 3.12, type hints required
- Use pytest for testing
- Follow PEP 8 style guide
- Database: PostgreSQL with SQLAlchemy
```

This is automatically loaded into every conversation session.

## ‚öôÔ∏è Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `OLLAMA_HOST` | `http://localhost:11434` | Ollama server URL |
| `OLLAMA_MODEL` | `qwen3-coder:30b` | Model to use |
| `TELEGRAM_BOT_TOKEN` | ‚Äî | Telegram bot token |
| `TELEGRAM_ALLOWED_USERS` | ‚Äî | Allowed user IDs (comma-separated) |
| `WORKSPACE_DIR` | `.` | Working directory for tools |

## üìÑ License

MIT
